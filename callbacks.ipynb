{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.13.0\n",
      "Keras version 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print( \"Tensorflow version\", tf.__version__)\n",
    "print( \"Keras version\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol quality  \n",
       "0         9.4     bad  \n",
       "1         9.8     bad  \n",
       "2         9.8     bad  \n",
       "3         9.8    good  \n",
       "4         9.4     bad  \n",
       "...       ...     ...  \n",
       "1594     10.5     bad  \n",
       "1595     11.2    good  \n",
       "1596     11.0    good  \n",
       "1597     10.2     bad  \n",
       "1598     11.0    good  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"wine.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   object \n",
      "dtypes: float64(11), object(1)\n",
      "memory usage: 150.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad', 'good'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'] = df['quality'].apply(lambda x : 1 if x == 'Good' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['quality']\n",
    "X = df.drop(columns=['quality'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.2 , random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.074</td>\n",
       "      <td>27.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>10.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.050</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.99740</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.093</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99860</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99740</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.096</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.99738</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.099</td>\n",
       "      <td>14.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.70</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>9.7</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.062</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.99830</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.062</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.99610</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.178</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.99600</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.87</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "68              9.3             0.320         0.57             2.0      0.074   \n",
       "663            10.1             0.280         0.46             1.8      0.050   \n",
       "76              8.8             0.410         0.64             2.2      0.093   \n",
       "380             8.3             0.260         0.42             2.0      0.080   \n",
       "761             9.3             0.655         0.26             2.0      0.096   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "360             8.2             0.700         0.23             2.0      0.099   \n",
       "709             9.7             0.310         0.47             1.6      0.062   \n",
       "439             7.0             0.620         0.18             1.5      0.062   \n",
       "174             7.3             0.380         0.21             2.0      0.080   \n",
       "1146            7.8             0.500         0.12             1.8      0.178   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "68                   27.0                  65.0  0.99690  3.28       0.79   \n",
       "663                   5.0                  13.0  0.99740  3.04       0.79   \n",
       "76                    9.0                  42.0  0.99860  3.54       0.66   \n",
       "380                  11.0                  27.0  0.99740  3.21       0.80   \n",
       "761                   5.0                  35.0  0.99738  3.25       0.42   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "360                  14.0                  81.0  0.99730  3.19       0.70   \n",
       "709                  13.0                  33.0  0.99830  3.27       0.66   \n",
       "439                   7.0                  50.0  0.99510  3.08       0.60   \n",
       "174                   7.0                  35.0  0.99610  3.33       0.47   \n",
       "1146                  6.0                  21.0  0.99600  3.28       0.87   \n",
       "\n",
       "      alcohol  \n",
       "68       10.7  \n",
       "663      10.2  \n",
       "76       10.5  \n",
       "380       9.4  \n",
       "761       9.6  \n",
       "...       ...  \n",
       "360       9.4  \n",
       "709      10.0  \n",
       "439       9.3  \n",
       "174       9.5  \n",
       "1146      9.8  \n",
       "\n",
       "[1279 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256 , input_dim = X_train.shape[1] , activation='relu'),\n",
    "    keras.layers.Dense(128 , activation='relu'),\n",
    "    keras.layers.Dense( 64 , activation='relu'),\n",
    "    keras.layers.Dense( 1 , activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile( optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               3072      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44289 (173.00 KB)\n",
      "Trainable params: 44289 (173.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_val , y_train , y_val = train_test_split(X_train , y_train , test_size=0.3 , random_state=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((895, 11), (320, 11))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train , y_train , epochs=30 , validation_data=(X_val , y_val) , batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 16ms/step - loss: 0.1805 - accuracy: 0.9687 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 9.3497e-04 - accuracy: 1.0000 - val_loss: 4.7962e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2.6404e-04 - accuracy: 1.0000 - val_loss: 3.2860e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.9013e-04 - accuracy: 1.0000 - val_loss: 2.5738e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.4386e-04 - accuracy: 1.0000 - val_loss: 2.0298e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.0923e-04 - accuracy: 1.0000 - val_loss: 1.5835e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 8.2433e-05 - accuracy: 1.0000 - val_loss: 1.2429e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 6.2781e-05 - accuracy: 1.0000 - val_loss: 9.8308e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 4.8230e-05 - accuracy: 1.0000 - val_loss: 7.9418e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.8064e-05 - accuracy: 1.0000 - val_loss: 6.4039e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3.0117e-05 - accuracy: 1.0000 - val_loss: 5.3212e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2.4457e-05 - accuracy: 1.0000 - val_loss: 4.4614e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.0084e-05 - accuracy: 1.0000 - val_loss: 3.8035e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.6779e-05 - accuracy: 1.0000 - val_loss: 3.2658e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.4131e-05 - accuracy: 1.0000 - val_loss: 2.8548e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.2155e-05 - accuracy: 1.0000 - val_loss: 2.4844e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.0466e-05 - accuracy: 1.0000 - val_loss: 2.1960e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 9.0654e-06 - accuracy: 1.0000 - val_loss: 1.9763e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 7.9713e-06 - accuracy: 1.0000 - val_loss: 1.7861e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.0686e-06 - accuracy: 1.0000 - val_loss: 1.6092e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 6.2874e-06 - accuracy: 1.0000 - val_loss: 1.4572e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 5.6298e-06 - accuracy: 1.0000 - val_loss: 1.3250e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 5.0730e-06 - accuracy: 1.0000 - val_loss: 1.2089e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 4.5801e-06 - accuracy: 1.0000 - val_loss: 1.1135e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 4.1589e-06 - accuracy: 1.0000 - val_loss: 1.0305e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3.7974e-06 - accuracy: 1.0000 - val_loss: 9.5470e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.4753e-06 - accuracy: 1.0000 - val_loss: 8.8893e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.1979e-06 - accuracy: 1.0000 - val_loss: 8.2786e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.9468e-06 - accuracy: 1.0000 - val_loss: 7.7442e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.7228e-06 - accuracy: 1.0000 - val_loss: 7.2713e-06 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_dim=X_train.shape[1], activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving logs at logs/fit\\log_2023_10_22_11_21_07\n"
     ]
    }
   ],
   "source": [
    "def get_log_path(log_dir = \"logs/fit\"):\n",
    "    filename = time.strftime(\"log_%Y_%m_%d_%H_%M_%S\")\n",
    "    logs_path = os.path.join(log_dir, filename)\n",
    "    print(f\"Saving logs at {logs_path}\")\n",
    "    return logs_path\n",
    "\n",
    "log_dir = get_log_path()\n",
    "tb_cb = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_st_cb = tf.keras.callbacks.EarlyStopping(patience=5 , restore_best_weights=True , monitor='val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Checkpoint Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"Model_ckpt.h5\"\n",
    "checkpointing_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path , save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 3.7328e-07 - accuracy: 1.0000 - val_loss: 1.4050e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.6089e-07 - accuracy: 1.0000 - val_loss: 1.3701e-06 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.5005e-07 - accuracy: 1.0000 - val_loss: 1.3272e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.3783e-07 - accuracy: 1.0000 - val_loss: 1.2958e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3.2751e-07 - accuracy: 1.0000 - val_loss: 1.2609e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.1758e-07 - accuracy: 1.0000 - val_loss: 1.2258e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.0708e-07 - accuracy: 1.0000 - val_loss: 1.1982e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.9852e-07 - accuracy: 1.0000 - val_loss: 1.1644e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.8921e-07 - accuracy: 1.0000 - val_loss: 1.1339e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.8011e-07 - accuracy: 1.0000 - val_loss: 1.1065e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.7191e-07 - accuracy: 1.0000 - val_loss: 1.0796e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.6409e-07 - accuracy: 1.0000 - val_loss: 1.0528e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.5615e-07 - accuracy: 1.0000 - val_loss: 1.0281e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.4884e-07 - accuracy: 1.0000 - val_loss: 1.0042e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.4157e-07 - accuracy: 1.0000 - val_loss: 9.8493e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.3537e-07 - accuracy: 1.0000 - val_loss: 9.5806e-07 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.2811e-07 - accuracy: 1.0000 - val_loss: 9.3784e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.2242e-07 - accuracy: 1.0000 - val_loss: 9.1278e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.1586e-07 - accuracy: 1.0000 - val_loss: 8.9177e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.0970e-07 - accuracy: 1.0000 - val_loss: 8.7450e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.0437e-07 - accuracy: 1.0000 - val_loss: 8.5327e-07 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.9867e-07 - accuracy: 1.0000 - val_loss: 8.3485e-07 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.9366e-07 - accuracy: 1.0000 - val_loss: 8.1512e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8802e-07 - accuracy: 1.0000 - val_loss: 8.0035e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8331e-07 - accuracy: 1.0000 - val_loss: 7.8315e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.7849e-07 - accuracy: 1.0000 - val_loss: 7.6779e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.7407e-07 - accuracy: 1.0000 - val_loss: 7.4908e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.6944e-07 - accuracy: 1.0000 - val_loss: 7.3298e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.6507e-07 - accuracy: 1.0000 - val_loss: 7.1823e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.6132e-07 - accuracy: 1.0000 - val_loss: 7.0096e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train , y_train , epochs=30 ,validation_data=(X_val, y_val), batch_size=32 , callbacks=[tb_cb , early_st_cb , checkpointing_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Model_2023_10_22_11_36_47_.h5 will be saved at trained_model\\Model_2023_10_22_11_36_47_.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trained_model\\\\Model_2023_10_22_11_36_47_.h5'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_model_path(Model_dir = \"trained_model\"):\n",
    "    os.makedirs(Model_dir , exist_ok=True)\n",
    "    filename = time.strftime(\"Model_%Y_%m_%d_%H_%M_%S_.h5\")\n",
    "    model_path = os.path.join(Model_dir , filename )\n",
    "    print(f\"Model {filename} will be saved at {model_path}\")\n",
    "    return model_path\n",
    "\n",
    "unique_path = save_model_path()\n",
    "unique_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model , unique_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.732818e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.404978e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.608908e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.370050e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.500513e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.327208e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.378307e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.295776e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.275100e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.260892e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.175834e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.225788e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.070755e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.198233e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.985194e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.164447e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.892117e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.133868e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.801109e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.106491e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.719104e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.079597e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.640863e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.052812e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.561505e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.028135e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.488351e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.004201e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.415709e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.849277e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.353713e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.580607e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.281064e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.378371e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.224237e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.127769e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.158595e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.917651e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.096975e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.744973e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.043691e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.532680e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.986709e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.348493e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.936592e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.151207e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.880187e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.003480e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.833065e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.831511e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.784935e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.677888e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.740702e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.490781e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.694381e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.329815e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.650697e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.182269e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.613194e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.009625e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  accuracy      val_loss  val_accuracy\n",
       "0   3.732818e-07       1.0  1.404978e-06           1.0\n",
       "1   3.608908e-07       1.0  1.370050e-06           1.0\n",
       "2   3.500513e-07       1.0  1.327208e-06           1.0\n",
       "3   3.378307e-07       1.0  1.295776e-06           1.0\n",
       "4   3.275100e-07       1.0  1.260892e-06           1.0\n",
       "5   3.175834e-07       1.0  1.225788e-06           1.0\n",
       "6   3.070755e-07       1.0  1.198233e-06           1.0\n",
       "7   2.985194e-07       1.0  1.164447e-06           1.0\n",
       "8   2.892117e-07       1.0  1.133868e-06           1.0\n",
       "9   2.801109e-07       1.0  1.106491e-06           1.0\n",
       "10  2.719104e-07       1.0  1.079597e-06           1.0\n",
       "11  2.640863e-07       1.0  1.052812e-06           1.0\n",
       "12  2.561505e-07       1.0  1.028135e-06           1.0\n",
       "13  2.488351e-07       1.0  1.004201e-06           1.0\n",
       "14  2.415709e-07       1.0  9.849277e-07           1.0\n",
       "15  2.353713e-07       1.0  9.580607e-07           1.0\n",
       "16  2.281064e-07       1.0  9.378371e-07           1.0\n",
       "17  2.224237e-07       1.0  9.127769e-07           1.0\n",
       "18  2.158595e-07       1.0  8.917651e-07           1.0\n",
       "19  2.096975e-07       1.0  8.744973e-07           1.0\n",
       "20  2.043691e-07       1.0  8.532680e-07           1.0\n",
       "21  1.986709e-07       1.0  8.348493e-07           1.0\n",
       "22  1.936592e-07       1.0  8.151207e-07           1.0\n",
       "23  1.880187e-07       1.0  8.003480e-07           1.0\n",
       "24  1.833065e-07       1.0  7.831511e-07           1.0\n",
       "25  1.784935e-07       1.0  7.677888e-07           1.0\n",
       "26  1.740702e-07       1.0  7.490781e-07           1.0\n",
       "27  1.694381e-07       1.0  7.329815e-07           1.0\n",
       "28  1.650697e-07       1.0  7.182269e-07           1.0\n",
       "29  1.613194e-07       1.0  7.009625e-07           1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGdCAYAAADNHANuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyeklEQVR4nO3de3zP9f//8ft7a0fswNiMZQ5zCnNeoyL2afGxHKqvWE5FEYWlWLHVp/pMilSUC4UOxKcD+USKRUXLYayTEcLqwybKxsamvV+/P/p599nHsPeM93PcrpfL63Kx1+v5er0e7+fldbm8756v5+v9slmWZQkAAMDF3FxdAAAAgEQoAQAAhiCUAAAAIxBKAACAEQglAADACIQSAABgBEIJAAAwAqEEAAAY4RpXF1AWdrtdBw8eVLVq1WSz2VxdDgAAKAPLsnT8+HGFhobKze3C4yCVIpQcPHhQYWFhri4DAACUw88//6y6detesF2lCCXVqlWT9OeH8vPzc3E1AACgLPLy8hQWFub4Hr+QShFKztyy8fPzI5QAAFDJlHXqBRNdAQCAEQglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARnA4lX3zxheLi4hQaGiqbzably5dfcJ/169erbdu28vLyUqNGjbRw4cJylAoAAK5kToeS/Px8RUZGavbs2WVqv2/fPv3973/XzTffrIyMDI0bN07Dhw/XJ5984nSxAADgyuX0u2969OihHj16lLn9nDlzVL9+fU2fPl2S1KxZM23YsEEvvPCCYmNjnT19hbHsdll5v7ns/AAAmMTmV102N9fO6rjkL+RLS0tTTExMiXWxsbEaN27cOfcpLCxUYWGh4++8vLwKr8vK+027rr+xwo8LAEBl1OTrL2ULCHJpDZc8EmVnZys4OLjEuuDgYOXl5enkyZOl7pOSkiJ/f3/HEhYWdqnLBAAALnbJR0rKIzExUQkJCY6/8/LyKjyY2Pyqq8nXX1boMQEAqKxsftVdXcKlDyUhISHKyckpsS4nJ0d+fn7y8fEpdR8vLy95eXld0rpsbm4uH6YCAAB/ueS3b6Kjo5Wamlpi3Zo1axQdHX2pTw0AACoRp0PJiRMnlJGRoYyMDEl/PvKbkZGhrKwsSX/eehk8eLCj/ciRI/XTTz/p0Ucf1c6dO/XKK6/oX//6l8aPH18xnwAAAFwRnA4lW7duVZs2bdSmTRtJUkJCgtq0aaOkpCRJ0qFDhxwBRZLq16+vlStXas2aNYqMjNT06dP12muvufRxYAAAYB6bZVmWq4u4kLy8PPn7+ys3N1d+fn6uLgcAAJSBs9/fvPsGAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQAARiCUAAAAIxBKAACAEQglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQAARiCUAAAAIxBKAACAEQglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABihXKFk9uzZCg8Pl7e3t6KiorR58+bztp85c6aaNGkiHx8fhYWFafz48Tp16lS5CgYAAFcmp0PJ0qVLlZCQoOTkZG3btk2RkZGKjY3V4cOHS22/ePFiTZo0ScnJycrMzNTrr7+upUuX6rHHHrvo4gEAwJXD6VAyY8YMjRgxQsOGDVPz5s01Z84c+fr6av78+aW2/+qrr9S5c2cNHDhQ4eHhuuWWWzRgwIALjq4AAICri1OhpKioSOnp6YqJifnrAG5uiomJUVpaWqn7dOrUSenp6Y4Q8tNPP2nVqlXq2bPnOc9TWFiovLy8EgsAALiyXeNM4yNHjqi4uFjBwcEl1gcHB2vnzp2l7jNw4EAdOXJEN9xwgyzL0h9//KGRI0ee9/ZNSkqKnnzySWdKAwAAldwlf/pm/fr1+uc//6lXXnlF27Zt0wcffKCVK1fqqaeeOuc+iYmJys3NdSw///zzpS4TAAC4mFMjJUFBQXJ3d1dOTk6J9Tk5OQoJCSl1nylTpmjQoEEaPny4JKlly5bKz8/Xfffdp8cff1xubmfnIi8vL3l5eTlTGgAAqOScGinx9PRUu3btlJqa6lhnt9uVmpqq6OjoUvcpKCg4K3i4u7tLkizLcrZeAABwhXJqpESSEhISNGTIELVv314dO3bUzJkzlZ+fr2HDhkmSBg8erDp16iglJUWSFBcXpxkzZqhNmzaKiorSnj17NGXKFMXFxTnCCQAAgNOhpH///vr111+VlJSk7OxstW7dWqtXr3ZMfs3KyioxMjJ58mTZbDZNnjxZ//nPf1SzZk3FxcXpmWeeqbhPAQAAKj2bVQnuoeTl5cnf31+5ubny8/NzdTkAAKAMnP3+5t03AADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQAARiCUAAAAIxBKAACAEQglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQAARiCUAAAAIxBKAACAEa5xdQEAADMVFxfr9OnTri4DBvPw8JC7u3uFHY9QAgAowbIsZWdn69ixY64uBZVAQECAQkJCZLPZLvpYhBIAQAlnAkmtWrXk6+tbIV82uPJYlqWCggIdPnxYklS7du2LPiahBADgUFxc7AgkNWrUcHU5MJyPj48k6fDhw6pVq9ZF38phoisAwOHMHBJfX18XV4LK4sy1UhHzjwglAICzcMsGZVWR1wqhBAAAGIFQAgC4InTt2lXjxo1zdRm4COUKJbNnz1Z4eLi8vb0VFRWlzZs3n7f9sWPHNHr0aNWuXVteXl5q3LixVq1aVa6CAQDAlcnpp2+WLl2qhIQEzZkzR1FRUZo5c6ZiY2O1a9cu1apV66z2RUVF+tvf/qZatWrpvffeU506dXTgwAEFBARURP0AAOAK4fRIyYwZMzRixAgNGzZMzZs315w5c+Tr66v58+eX2n7+/Pn67bfftHz5cnXu3Fnh4eHq0qWLIiMjL7p4AABK8/vvv2vw4MEKDAyUr6+vevTood27dzu2HzhwQHFxcQoMDFSVKlV03XXXOUbwf//9d8XHx6tmzZry8fFRRESEFixY4KqPclVxaqSkqKhI6enpSkxMdKxzc3NTTEyM0tLSSt1nxYoVio6O1ujRo/Xhhx+qZs2aGjhwoCZOnHjO55kLCwtVWFjo+DsvL8+ZMgEAFciyLJ08XXzZz+vj4V7uJzuGDh2q3bt3a8WKFfLz89PEiRPVs2dP7dixQx4eHho9erSKior0xRdfqEqVKtqxY4eqVq0qSZoyZYp27Nihjz/+WEFBQdqzZ49OnjxZkR8N5+BUKDly5IiKi4sVHBxcYn1wcLB27txZ6j4//fSTPvvsM8XHx2vVqlXas2ePHnjgAZ0+fVrJycml7pOSkqInn3zSmdIAAJfIydPFap70yWU/745/xMrX0/nf+DwTRjZu3KhOnTpJkhYtWqSwsDAtX75cd955p7KysnT77berZcuWkqQGDRo49s/KylKbNm3Uvn17SVJ4ePjFfxiUySV/+sZut6tWrVqaO3eu2rVrp/79++vxxx/XnDlzzrlPYmKicnNzHcvPP/98qcsEAFwhMjMzdc011ygqKsqxrkaNGmrSpIkyMzMlSQ899JCefvppde7cWcnJyfr2228dbUeNGqUlS5aodevWevTRR/XVV19d9s9wtXIqggYFBcnd3V05OTkl1ufk5CgkJKTUfWrXrn3WWwSbNWum7OxsFRUVydPT86x9vLy85OXl5UxpAIBLxMfDXTv+EeuS814qw4cPV2xsrFauXKlPP/1UKSkpmj59uh588EH16NFDBw4c0KpVq7RmzRp1795do0eP1vPPP3/J6sGfnBop8fT0VLt27ZSamupYZ7fblZqaqujo6FL36dy5s/bs2SO73e5Y9+OPP6p27dqlBhIAgFlsNpt8Pa+57Et555M0a9ZMf/zxhzZt2uRYd/ToUe3atUvNmzd3rAsLC9PIkSP1wQcf6OGHH9a8efMc22rWrKkhQ4bo7bff1syZMzV37tzydyDKzOnbNwkJCZo3b57eeOMNZWZmatSoUcrPz9ewYcMkSYMHDy4xEXbUqFH67bffNHbsWP34449auXKl/vnPf2r06NEV9ykAAPj/IiIi1Lt3b40YMUIbNmzQN998o7vvvlt16tRR7969JUnjxo3TJ598on379mnbtm1at26dmjVrJklKSkrShx9+qD179uiHH37QRx995NiGS8vpGUT9+/fXr7/+qqSkJGVnZ6t169ZavXq1Y/JrVlaW3Nz+yjphYWH65JNPNH78eLVq1Up16tTR2LFjNXHixIr7FAAA/JcFCxZo7Nix6tWrl4qKinTTTTdp1apV8vDwkPTn25BHjx6tX375RX5+frr11lv1wgsvSPrzrkBiYqL2798vHx8f3XjjjVqyZIkrP85Vw2ZZluXqIi4kLy9P/v7+ys3NlZ+fn6vLAYAr1qlTp7Rv3z7Vr19f3t7eri4HlcD5rhlnv7959w0AADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQDgEjh9+rSrS6h0CCUAgCvC6tWrdcMNNyggIEA1atRQr169tHfvXsf2X375RQMGDFD16tVVpUoVtW/fXps2bXJs//e//60OHTrI29tbQUFB6tu3r2ObzWbT8uXLS5wvICBACxculCTt379fNptNS5cuVZcuXeTt7a1Fixbp6NGjGjBggOrUqSNfX1+1bNlS77zzTonj2O12TZs2TY0aNZKXl5euvfZaPfPMM5Kkbt26acyYMSXa//rrr/L09FRqampFdJtRrnF1AQAAw1mWdLrg8p/Xw1ey2crcPD8/XwkJCWrVqpVOnDihpKQk9e3bVxkZGSooKFCXLl1Up04drVixQiEhIdq2bZvsdrskaeXKlerbt68ef/xxvfnmmyoqKtKqVaucLnnSpEmaPn262rRpI29vb506dUrt2rXTxIkT5efnp5UrV2rQoEFq2LChOnbsKElKTEzUvHnz9MILL+iGG27QoUOHtHPnTknS8OHDNWbMGE2fPl1eXl6SpLffflt16tRRt27dnK7PdDbLsixXF3Ehzr76GABQPqW+hr4oX/pn6OUv5rGDkmeVcu9+5MgR1axZU999952++uorTZgwQfv371f16tXPatupUyc1aNBAb7/9dqnHstlsWrZsmfr06eNYFxAQoJkzZ2ro0KHav3+/6tevr5kzZ2rs2LHnratXr15q2rSpnn/+eR0/flw1a9bUrFmzNHz48LPanjp1SqGhoZozZ47+7//+T5IUGRmpfv36KTk52YneuHRKvWb+P2e/v7l9AwC4IuzevVsDBgxQgwYN5Ofnp/DwcElSVlaWMjIy1KZNm1IDiSRlZGSoe/fuF11D+/btS/xdXFysp556Si1btlT16tVVtWpVffLJJ8rKypIkZWZmqrCw8Jzn9vb21qBBgzR//nxJ0rZt2/T9999r6NChF12ribh9AwA4Pw/fP0ctXHFeJ8TFxalevXqaN2+eQkNDZbfb1aJFCxUVFcnHx+e8+15ou81m0//eWChtImuVKiVHdp577jm9+OKLmjlzplq2bKkqVapo3LhxKioqKtN5pT9v4bRu3Vq//PKLFixYoG7duqlevXoX3K8yYqQEAHB+Ntuft1Eu9+LEfJKjR49q165dmjx5srp3765mzZrp999/d2xv1aqVMjIy9Ntvv5W6f6tWrc47cbRmzZo6dOiQ4+/du3eroODC82w2btyo3r176+6771ZkZKQaNGigH3/80bE9IiJCPj4+5z13y5Yt1b59e82bN0+LFy/WPffcc8HzVlaEEgBApRcYGKgaNWpo7ty52rNnjz777DMlJCQ4tg8YMEAhISHq06ePNm7cqJ9++knvv/++0tLSJEnJycl65513lJycrMzMTH333Xd69tlnHft369ZNs2bN0vbt27V161aNHDlSHh4eF6wrIiJCa9as0VdffaXMzEzdf//9ysnJcWz39vbWxIkT9eijj+rNN9/U3r179fXXX+v1118vcZzhw4dr6tSpsiyrxFNBVxpCCQCg0nNzc9OSJUuUnp6uFi1aaPz48Xruuecc2z09PfXpp5+qVq1a6tmzp1q2bKmpU6fK3d1dktS1a1e9++67WrFihVq3bq1u3bpp8+bNjv2nT5+usLAw3XjjjRo4cKAmTJggX98L316aPHmy2rZtq9jYWHXt2tURjP7blClT9PDDDyspKUnNmjVT//79dfjw4RJtBgwYoGuuuUYDBgw4azLplYSnbwAADud7kgKus3//fjVs2FBbtmxR27ZtXV1OCRX59A0TXQEAMNTp06d19OhRTZ48Wddff71xgaSicfsGAABDbdy4UbVr19aWLVs0Z84cV5dzyTFSAgCAobp27XrWo8hXMkZKAACAEQglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAEBSeHi4Zs6cWaa2NptNy5cvv6T1XI0IJQAAwAiEEgAAYARCCQCg0ps7d65CQ0Nlt9tLrO/du7fuuece7d27V71791ZwcLCqVq2qDh06aO3atRV2/u+++07dunWTj4+PatSoofvuu08nTpxwbF+/fr06duyoKlWqKCAgQJ07d9aBAwckSd98841uvvlmVatWTX5+fmrXrp22bt1aYbVVJoQSAMB5WZalgtMFl31x5ufV77zzTh09elTr1q1zrPvtt9+0evVqxcfH68SJE+rZs6dSU1O1fft23XrrrYqLi1NWVtZF909+fr5iY2MVGBioLVu26N1339XatWs1ZswYSdIff/yhPn36qEuXLvr222+Vlpam++67TzabTZIUHx+vunXrasuWLUpPT9ekSZPk4eFx0XVVRrz7BgBwXif/OKmoxVGX/bybBm6Sr4dvmdoGBgaqR48eWrx4sbp37y5Jeu+99xQUFKSbb75Zbm5uioyMdLR/6qmntGzZMq1YscIRHspr8eLFOnXqlN58801VqVJFkjRr1izFxcXp2WeflYeHh3Jzc9WrVy81bNhQktSsWTPH/llZWXrkkUfUtGlTSVJERMRF1VOZMVICALgixMfH6/3331dhYaEkadGiRbrrrrvk5uamEydOaMKECWrWrJkCAgJUtWpVZWZmVshISWZmpiIjIx2BRJI6d+4su92uXbt2qXr16ho6dKhiY2MVFxenF198UYcOHXK0TUhI0PDhwxUTE6OpU6dq7969F11TZcVICQDgvHyu8dGmgZtccl5nxMXFybIsrVy5Uh06dNCXX36pF154QZI0YcIErVmzRs8//7waNWokHx8f3XHHHSoqKroUpZ9lwYIFeuihh7R69WotXbpUkydP1po1a3T99dfriSee0MCBA7Vy5Up9/PHHSk5O1pIlS9S3b9/LUptJCCUAgPOy2Wxlvo3iSt7e3urXr58WLVqkPXv2qEmTJmrbtq0kaePGjRo6dKjji/7EiRPav39/hZy3WbNmWrhwofLz8x2jJRs3bpSbm5uaNGniaNemTRu1adNGiYmJio6O1uLFi3X99ddLkho3bqzGjRtr/PjxGjBggBYsWHBVhhJu3wAArhjx8fFauXKl5s+fr/j4eMf6iIgIffDBB8rIyNA333yjgQMHnvWkzsWc09vbW0OGDNH333+vdevW6cEHH9SgQYMUHBysffv2KTExUWlpaTpw4IA+/fRT7d69W82aNdPJkyc1ZswYrV+/XgcOHNDGjRu1ZcuWEnNOriaMlAAArhjdunVT9erVtWvXLg0cONCxfsaMGbrnnnvUqVMnBQUFaeLEicrLy6uQc/r6+uqTTz7R2LFj1aFDB/n6+ur222/XjBkzHNt37typN954Q0ePHlXt2rU1evRo3X///frjjz909OhRDR48WDk5OQoKClK/fv305JNPVkhtlY3NcuaZKxfJy8uTv7+/cnNz5efn5+pyAOCKderUKe3bt0/169eXt7e3q8tBJXC+a8bZ729u3wAAACMQSgAA+C+LFi1S1apVS12uu+46V5d3RWNOCQAA/+W2225TVFTpPxZ3tf7S6uVCKAEA4L9Uq1ZN1apVc3UZVyVu3wAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAASeHh4Zo5c6ary7iqEUoAAIARCCUAAFRyxcXFFfbWY1cilAAAKr25c+cqNDT0rC/m3r1765577tHevXvVu3dvBQcHq2rVqurQoYPWrl1b7vPNmDFDLVu2VJUqVRQWFqYHHnhAJ06cKNFm48aN6tq1q3x9fRUYGKjY2Fj9/vvvkiS73a5p06apUaNG8vLy0rXXXqtnnnlGkrR+/XrZbDYdO3bMcayMjAzZbDbt379fkrRw4UIFBARoxYoVat68uby8vJSVlaUtW7bob3/7m4KCguTv768uXbpo27ZtJeo6duyY7r//fgUHB8vb21stWrTQRx99pPz8fPn5+em9994r0X758uWqUqWKjh8/Xu7+KitCCQDgvCzLkr2g4LIvzrzE/s4779TRo0e1bt06x7rffvtNq1evVnx8vE6cOKGePXsqNTVV27dv16233qq4uDhlZWWVq0/c3Nz00ksv6YcfftAbb7yhzz77TI8++qhje0ZGhrp3767mzZsrLS1NGzZsUFxcnIqLiyVJiYmJmjp1qqZMmaIdO3Zo8eLFCg4OdqqGgoICPfvss3rttdf0ww8/qFatWjp+/LiGDBmiDRs26Ouvv1ZERIR69uzpCBR2u109evTQxo0b9fbbb2vHjh2aOnWq3N3dVaVKFd11111asGBBifMsWLBAd9xxx2X5ldty/cz87Nmz9dxzzyk7O1uRkZF6+eWX1bFjxwvut2TJEg0YMEC9e/fW8uXLy3NqAMBlZp08qV1t21328zbZli6br2+Z2gYGBqpHjx5avHixunfvLkl67733FBQUpJtvvllubm6KjIx0tH/qqae0bNkyrVixQmPGjHG6tnHjxjn+HR4erqefflojR47UK6+8IkmaNm2a2rdv7/hbkuNlfsePH9eLL76oWbNmaciQIZKkhg0b6oYbbnCqhtOnT+uVV14p8bm6detWos3cuXMVEBCgzz//XL169dLatWu1efNmZWZmqnHjxpKkBg0aONoPHz5cnTp10qFDh1S7dm0dPnxYq1atuqhRJWc4PVKydOlSJSQkKDk5Wdu2bVNkZKRiY2N1+PDh8+63f/9+TZgwQTfeeGO5iwUA4Fzi4+P1/vvvq7CwUNKfb/u966675ObmphMnTmjChAlq1qyZAgICVLVqVWVmZpZ7pGTt2rXq3r276tSpo2rVqmnQoEE6evSoCgoKJP01UlKazMxMFRYWnnN7WXl6eqpVq1Yl1uXk5GjEiBGKiIiQv7+//Pz8dOLECcfnzMjIUN26dR2B5H917NhR1113nd544w1J0ttvv6169erppptuuqhay8rpkZIZM2ZoxIgRGjZsmCRpzpw5WrlypebPn69JkyaVuk9xcbHi4+P15JNP6ssvvyxxnwwAYDabj4+abEt3yXmdERcXJ8uytHLlSnXo0EFffvmlXnjhBUnShAkTtGbNGj3//PNq1KiRfHx8dMcdd6ioqMjpuvbv369evXpp1KhReuaZZ1S9enVt2LBB9957r4qKiuTr6yuf89R+vm3Sn7eGJJW4fXX69OlSj2Oz2UqsGzJkiI4ePaoXX3xR9erVk5eXl6Kjox2f80Lnlv4cLZk9e7YmTZqkBQsWaNiwYWed51JxaqSkqKhI6enpiomJ+esAbm6KiYlRWlraOff7xz/+oVq1aunee+8t03kKCwuVl5dXYgEAuIbNZpObr+9lX5z9IvT29la/fv20aNEivfPOO2rSpInatm0r6c9Jp0OHDlXfvn3VsmVLhYSEOCaNOis9PV12u13Tp0/X9ddfr8aNG+vgwYMl2rRq1Uqpqaml7h8RESEfH59zbq9Zs6Yk6dChQ451GRkZZapt48aNeuihh9SzZ09dd9118vLy0pEjR0rU9csvv+jHH3885zHuvvtuHThwQC+99JJ27NjhuMV0OTgVSo4cOaLi4uKzJuMEBwcrOzu71H02bNig119/XfPmzSvzeVJSUuTv7+9YwsLCnCkTAHCVio+Pd4zex8fHO9ZHRETogw8+UEZGhr755hsNHDiw3I/QNmrUSKdPn9bLL7+sn376SW+99ZbmzJlTok1iYqK2bNmiBx54QN9++6127typV199VUeOHJG3t7cmTpyoRx99VG+++ab27t2rr7/+Wq+//rrj+GFhYXriiSe0e/durVy5UtOnTy9TbREREXrrrbeUmZmpTZs2KT4+vsToSJcuXXTTTTfp9ttv15o1a7Rv3z59/PHHWr16taNNYGCg+vXrp0ceeUS33HKL6tatW65+Ko9L+vTN8ePHNWjQIM2bN09BQUFl3i8xMVG5ubmO5eeff76EVQIArhTdunVT9erVtWvXLg0cONCxfsaMGQoMDFSnTp0UFxen2NhYxyiKsyIjIzVjxgw9++yzatGihRYtWqSUlJQSbRo3bqxPP/1U33zzjTp27Kjo6Gh9+OGHuuaaP2dNTJkyRQ8//LCSkpLUrFkz9e/f3zE308PDQ++884527typVq1a6dlnn9XTTz9dptpef/11/f7772rbtq0GDRqkhx56SLVq1SrR5v3331eHDh00YMAANW/eXI8++qjjqaAzztyKuueee8rVR+Vls5x45urMvbL33ntPffr0cawfMmSIjh07pg8//LBE+4yMDLVp00bu7u6OdWeSqZubm3bt2qWGDRte8Lx5eXny9/dXbm6u/Pz8ylouAMBJp06d0r59+1S/fn15e3u7uhy4yFtvvaXx48fr4MGD8vT0PG/b810zzn5/OzVS4unpqXbt2pW4D2a325Wamqro6Oiz2jdt2lTfffedMjIyHMttt92mm2++WRkZGdyWAQDAIAUFBdq7d6+mTp2q+++//4KBpKI5ffsmISFB8+bN0xtvvKHMzEyNGjVK+fn5jqdxBg8erMTEREly/FLcfy8BAQGqVq2aWrRocdk/LAAAF7Jo0SJVrVq11OXMb41cqaZNm6amTZsqJCTE8V1+OTn9SHD//v3166+/KikpSdnZ2WrdurVWr17tmPyalZXleJwJAIDK5rbbblNUVFSp2zw8PC5zNZfXE088oSeeeMJl53dqTomrMKcEAC4P5pTAWS6bUwIAAHCpEEoAAGepBIPoMERFXiuEEgCAw5k5E2fe4QJcyJlrpSLm25TrLcEAgCuTu7u7AgICHD/k5VuOn3vH1cGyLBUUFOjw4cMKCAgo8Ztk5UUoAQCUEBISIkkXfPs7IEkBAQGOa+ZiEUoAACXYbDbVrl1btWrVKvXttMAZHh4eFTJCcgahBABQKnd39wr9wgEuhImuAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQAARiCUAAAAIxBKAACAEQglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQAARiCUAAAAIxBKAACAEQglAADACOUKJbNnz1Z4eLi8vb0VFRWlzZs3n7PtvHnzdOONNyowMFCBgYGKiYk5b3sAAHB1cjqULF26VAkJCUpOTta2bdsUGRmp2NhYHT58uNT269ev14ABA7Ru3TqlpaUpLCxMt9xyi/7zn/9cdPEAAODKYbMsy3Jmh6ioKHXo0EGzZs2SJNntdoWFhenBBx/UpEmTLrh/cXGxAgMDNWvWLA0ePLhM58zLy5O/v79yc3Pl5+fnTLkAAMBFnP3+dmqkpKioSOnp6YqJifnrAG5uiomJUVpaWpmOUVBQoNOnT6t69ernbFNYWKi8vLwSCwAAuLI5FUqOHDmi4uJiBQcHl1gfHBys7OzsMh1j4sSJCg0NLRFs/ldKSor8/f0dS1hYmDNlAgCASuiyPn0zdepULVmyRMuWLZO3t/c52yUmJio3N9ex/Pzzz5exSgAA4ArXONM4KChI7u7uysnJKbE+JydHISEh5933+eef19SpU7V27Vq1atXqvG29vLzk5eXlTGkAAKCSc2qkxNPTU+3atVNqaqpjnd1uV2pqqqKjo8+537Rp0/TUU09p9erVat++ffmrBQAAVyynRkokKSEhQUOGDFH79u3VsWNHzZw5U/n5+Ro2bJgkafDgwapTp45SUlIkSc8++6ySkpK0ePFihYeHO+aeVK1aVVWrVq3AjwIAACozp0NJ//799euvvyopKUnZ2dlq3bq1Vq9e7Zj8mpWVJTe3vwZgXn31VRUVFemOO+4ocZzk5GQ98cQTF1c9AAC4Yjj9OyWuwO+UAABQ+VzS3ykBAAC4VAglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQAARiCUAAAAIxBKAACAEQglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABiBUAIAAIxAKAEAAEYglAAAACMQSgAAgBEIJQAAwAiEEgAAYARCCQAAMAKhBAAAGIFQAgAAjEAoAQAARiCUAAAAIxBKAACAEQglAADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjlCuUzJ49W+Hh4fL29lZUVJQ2b9583vbvvvuumjZtKm9vb7Vs2VKrVq0qV7EAAODK5XQoWbp0qRISEpScnKxt27YpMjJSsbGxOnz4cKntv/rqKw0YMED33nuvtm/frj59+qhPnz76/vvvL7p4AABw5bBZlmU5s0NUVJQ6dOigWbNmSZLsdrvCwsL04IMPatKkSWe179+/v/Lz8/XRRx851l1//fVq3bq15syZU6Zz5uXlyd/fX7m5ufLz83Om3HOy2+36/VR+hRwLAIDKLtC7itzcKnZWh7Pf39c4c/CioiKlp6crMTHRsc7NzU0xMTFKS0srdZ+0tDQlJCSUWBcbG6vly5ef8zyFhYUqLCx0/J2Xl+dMmWXy+6l8dX23U4UfFwCAymj9nV+phm81l9bgVCQ6cuSIiouLFRwcXGJ9cHCwsrOzS90nOzvbqfaSlJKSIn9/f8cSFhbmTJkAAKAScmqk5HJJTEwsMbqSl5dX4cEk0LuK1t/5VYUeEwCAyirQu4qrS3AulAQFBcnd3V05OTkl1ufk5CgkJKTUfUJCQpxqL0leXl7y8vJypjSnubm5uXyYCgAA/MWp2zeenp5q166dUlNTHevsdrtSU1MVHR1d6j7R0dEl2kvSmjVrztkeAABcnZy+fZOQkKAhQ4aoffv26tixo2bOnKn8/HwNGzZMkjR48GDVqVNHKSkpkqSxY8eqS5cumj59uv7+979ryZIl2rp1q+bOnVuxnwQAAFRqToeS/v3769dff1VSUpKys7PVunVrrV692jGZNSsrq8QjRZ06ddLixYs1efJkPfbYY4qIiNDy5cvVokWLivsUAACg0nP6d0pc4VL8TgkAALi0nP3+5t03AADACIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAITv/MvCuc+dHZvLw8F1cCAADK6sz3dll/PL5ShJLjx49LksLCwlxcCQAAcNbx48fl7+9/wXaV4t03drtdBw8eVLVq1WSz2SrsuHl5eQoLC9PPP//MO3WcQL+VD/3mPPqsfOi38qHfyud8/WZZlo4fP67Q0NASL+s9l0oxUuLm5qa6detesuP7+flxAZYD/VY+9Jvz6LPyod/Kh34rn3P1W1lGSM5goisAADACoQQAABjhqg4lXl5eSk5OlpeXl6tLqVTot/Kh35xHn5UP/VY+9Fv5VGS/VYqJrgAA4Mp3VY+UAAAAcxBKAACAEQglAADACIQSAABghKs6lMyePVvh4eHy9vZWVFSUNm/e7OqSjPbEE0/IZrOVWJo2berqsozzxRdfKC4uTqGhobLZbFq+fHmJ7ZZlKSkpSbVr15aPj49iYmK0e/du1xRriAv12dChQ8+69m699VbXFGuIlJQUdejQQdWqVVOtWrXUp08f7dq1q0SbU6dOafTo0apRo4aqVq2q22+/XTk5OS6q2Axl6beuXbuedb2NHDnSRRWb4dVXX1WrVq0cP5AWHR2tjz/+2LG9oq61qzaULF26VAkJCUpOTta2bdsUGRmp2NhYHT582NWlGe26667ToUOHHMuGDRtcXZJx8vPzFRkZqdmzZ5e6fdq0aXrppZc0Z84cbdq0SVWqVFFsbKxOnTp1mSs1x4X6TJJuvfXWEtfeO++8cxkrNM/nn3+u0aNH6+uvv9aaNWt0+vRp3XLLLcrPz3e0GT9+vP7973/r3Xff1eeff66DBw+qX79+Lqza9crSb5I0YsSIEtfbtGnTXFSxGerWraupU6cqPT1dW7duVbdu3dS7d2/98MMPkirwWrOuUh07drRGjx7t+Lu4uNgKDQ21UlJSXFiV2ZKTk63IyEhXl1GpSLKWLVvm+Ntut1shISHWc88951h37Ngxy8vLy3rnnXdcUKF5/rfPLMuyhgwZYvXu3dsl9VQWhw8ftiRZn3/+uWVZf15XHh4e1rvvvutok5mZaUmy0tLSXFWmcf633yzLsrp06WKNHTvWdUVVEoGBgdZrr71WodfaVTlSUlRUpPT0dMXExDjWubm5KSYmRmlpaS6szHy7d+9WaGioGjRooPj4eGVlZbm6pEpl3759ys7OLnHt+fv7KyoqimvvAtavX69atWqpSZMmGjVqlI4ePerqkoySm5srSapevbokKT09XadPny5xrTVt2lTXXnst19p/+d9+O2PRokUKCgpSixYtlJiYqIKCAleUZ6Ti4mItWbJE+fn5io6OrtBrrVK8kK+iHTlyRMXFxQoODi6xPjg4WDt37nRRVeaLiorSwoUL1aRJEx06dEhPPvmkbrzxRn3//feqVq2aq8urFLKzsyWp1GvvzDac7dZbb1W/fv1Uv3597d27V4899ph69OihtLQ0ubu7u7o8l7Pb7Ro3bpw6d+6sFi1aSPrzWvP09FRAQECJtlxrfymt3yRp4MCBqlevnkJDQ/Xtt99q4sSJ2rVrlz744AMXVut63333naKjo3Xq1ClVrVpVy5YtU/PmzZWRkVFh19pVGUpQPj169HD8u1WrVoqKilK9evX0r3/9S/fee68LK8OV7q677nL8u2XLlmrVqpUaNmyo9evXq3v37i6szAyjR4/W999/zxwvJ52r3+677z7Hv1u2bKnatWure/fu2rt3rxo2bHi5yzRGkyZNlJGRodzcXL333nsaMmSIPv/88wo9x1V5+yYoKEju7u5nzQzOyclRSEiIi6qqfAICAtS4cWPt2bPH1aVUGmeuL669i9OgQQMFBQVx7UkaM2aMPvroI61bt05169Z1rA8JCVFRUZGOHTtWoj3X2p/O1W+liYqKkqSr/nrz9PRUo0aN1K5dO6WkpCgyMlIvvvhihV5rV2Uo8fT0VLt27ZSamupYZ7fblZqaqujoaBdWVrmcOHFCe/fuVe3atV1dSqVRv359hYSElLj28vLytGnTJq49J/zyyy86evToVX3tWZalMWPGaNmyZfrss89Uv379EtvbtWsnDw+PEtfarl27lJWVdVVfaxfqt9JkZGRI0lV9vZXGbrersLCwYq+1ip2LW3ksWbLE8vLyshYuXGjt2LHDuu+++6yAgAArOzvb1aUZ6+GHH7bWr19v7du3z9q4caMVExNjBQUFWYcPH3Z1aUY5fvy4tX37dmv79u2WJGvGjBnW9u3brQMHDliWZVlTp061AgICrA8//ND69ttvrd69e1v169e3Tp486eLKXed8fXb8+HFrwoQJVlpamrVv3z5r7dq1Vtu2ba2IiAjr1KlTri7dZUaNGmX5+/tb69evtw4dOuRYCgoKHG1GjhxpXXvttdZnn31mbd261YqOjraio6NdWLXrXajf9uzZY/3jH/+wtm7dau3bt8/68MMPrQYNGlg33XSTiyt3rUmTJlmff/65tW/fPuvbb7+1Jk2aZNlsNuvTTz+1LKvirrWrNpRYlmW9/PLL1rXXXmt5enpaHTt2tL7++mtXl2S0/v37W7Vr17Y8PT2tOnXqWP3797f27Nnj6rKMs27dOkvSWcuQIUMsy/rzseApU6ZYwcHBlpeXl9W9e3dr165dri3axc7XZwUFBdYtt9xi1axZ0/Lw8LDq1atnjRgx4qr/D0Rp/SXJWrBggaPNyZMnrQceeMAKDAy0fH19rb59+1qHDh1yXdEGuFC/ZWVlWTfddJNVvXp1y8vLy2rUqJH1yCOPWLm5ua4t3MXuueceq169epanp6dVs2ZNq3v37o5AYlkVd63ZLMuyyjlyAwAAUGGuyjklAADAPIQSAABgBEIJAAAwAqEEAAAYgVACAACMQCgBAABGIJQAAAAjEEoAAIARCCUAAMAIhBIAAGAEQgkAADACoQQAABjh/wEPXqA+DBPM+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5361e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.536053559902939e-07, 1.0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3df68028e51ce44f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3df68028e51ce44f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 256)               3072      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44289 (173.00 KB)\n",
      "Trainable params: 44289 (173.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
